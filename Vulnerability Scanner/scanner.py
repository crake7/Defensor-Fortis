#!/usr/bin/env python

import requests
import re
import urllib.parse as urlparse
from bs4 import BeautifulSoup

class Scanner:
    def __init__(self, url, ignore_links):
        """Starts a session with web page."""
        self.links_to_ignore = ignore_links
        self.target = url
        self.links_list = []
        #In case you know the Login info:
        self.session = requests.Session()

    def extract_links(self, url):
       """#Extract all LINKS from page, we split the pattern (remove-word-?:)(non-greedy-?)"""
       # response = requests.get(url)
       response = self.session.get(url) #Get request on session created
    # print(response.content)
       return re.findall('(?:href=")(.*?)"', response.content.decode(errors="ignore"))
       # return href_links

    def crawl(self, url=None):
        """Read HTML page and create unique-value list with absolute URL's."""
        #We set first call to do not take a value; this will be ignored when recursive calling.
        if url == None:
            url = self.target
        href_links = self.extract_links(url)
        for link in href_links:
            # link = urljoin(url, link)
            link = urlparse.urljoin(url, link)
            if "#" in link:
                link = link.split("#")[0]
            if self.target in link and link not in self.links_list and link not in self.links_to_ignore:
                self.links_list.append(link)
                print(link)
                self.crawl(link)

    def extract_forms(self, url):
        """Extract <form> attributes from URL's HTML page using bs4 parser"""
        response = self.session.get(url)
        parsed_html = BeautifulSoup(response.content, "html5lib" )
        return parsed_html.find_all("form")

    def submit_form(self, form, value, url):
        """Submit input "value" to <form> attribute in URL's HTML page.
        IT'll get <action>, <method>, <inputs: name, type and value> from code."""
        action = form.get("action")
        POST_url = urlparse.urljoin(url, action)
        method = form.get("method")

        inputs_list = form.find_all("input")
        POST_data ={}
        for input in inputs_list:
            input_name = input.get("name")
            input_type = input.get("type")
            input_value = input.get("value")
            if input_type == "text":
                input_value = value
            POST_data[input_name] = input_value

            #As not all <method> are POST, it'll check and either POST or GET from session.
        if method == "post":
            return self.session.post(POST_url, data=POST_data)
        return self.session.get(POST_url, params=POST_data)

    def run_scanner(self):
        """Iterate on all target links collected on CRAWLER"""
        for link in self.links_list:
            forms = self.extract_forms(link)
            #This means we can send data to web server using POST request
            for form in forms:
                print("\nTesting <form> in: " + link)
                is_vulnerable_to_xss = self.test_xss_in_form(form, link)
                if is_vulnerable_to_xss:
                    print("\nXSS found in: " + str(link) + " the following <form>: ")
                    print(form)
                #Insert ADDITIONAL methods to test vulnerabilities

            if "=" in link:
                #This means the link sends data to web server using GET request
                print("\nTesting URL: " + link)
                is_vulnerable_to_xss = self.test_xss_in_link(link)
                if is_vulnerable_to_xss:
                    print("\nXSS found in: " + str(link))

                #Insert ADDITIONAL methods to test vulnerabilities

    def test_xss_in_form(self, form, url):
        """Method to discover XSS in any <form> of URL provided."""
        xss_test_script = "<sCript>alert('._.')</scriPt>"
        response = self.submit_form(form, xss_test_script, url)
        return xss_test_script.encode() in response.content

    def test_xss_in_link(self, url):
        """Method to discover any XSS vulnerability in link provided"""
        xss_test_script = "<sCript>alert('._.')</scriPt>"
        url = url.replace("=", "=" + xss_test_script)
        response = self.session.get(url)
        return xss_test_script.encode() in response.content
